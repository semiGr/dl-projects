{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Optimal Stopping - Dice problem - Implementation with tensorflow estimator \n",
    "\n",
    "#### Work is in progress... updates are expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import scipy\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample size for training \n",
    "M = 10000\n",
    "\n",
    "# create a sample of M x 3\n",
    "# In this example we only consider 3 tosses, hence only two steps with choices to stop at\n",
    "dice = np.random.randint(low=1, high=7, size=(M, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 samples: \n",
      "[[1 3 3]\n",
      " [3 6 5]\n",
      " [2 1 3]\n",
      " [5 3 2]\n",
      " [3 2 4]\n",
      " [1 1 2]\n",
      " [5 4 5]\n",
      " [3 2 6]\n",
      " [4 6 3]\n",
      " [2 6 6]]\n"
     ]
    }
   ],
   "source": [
    "# see the first 10 paths from the samples generated above\n",
    "print(\"The first 10 samples: \")\n",
    "print(dice[:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input function for training with estimator, and use the dice np dataset \n",
    "def numpy_train_input_fn(dice): \n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"t0\": np.reshape(dice[:, 0].astype(float), (len(dice[:, 0]), 1)), \n",
    "           \"t1\": np.reshape(dice[:, 1].astype(float), (len(dice[:, 1]), 1)), \n",
    "           \"t2\": np.reshape(dice[:, 2].astype(float), (len(dice[:, 2]), 1))},\n",
    "        batch_size = 64, \n",
    "        num_epochs = 30, \n",
    "        shuffle = True, \n",
    "        queue_capacity = 1000\n",
    "    )\n",
    "\n",
    "# define input function for evaluation\n",
    "def numpy_eval_input_fn(dice):\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"t0\": np.reshape(dice[:, 0].astype(float), (len(dice[:, 0]), 1)), \n",
    "           \"t1\": np.reshape(dice[:, 1].astype(float), (len(dice[:, 1]), 1)), \n",
    "           \"t2\": np.reshape(dice[:, 2].astype(float), (len(dice[:, 2]), 1))},\n",
    "        num_epochs = 1, \n",
    "        shuffle = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model_fn(features, mode, params):  \n",
    "    \n",
    "    \"\"\"Defining the custon architecture\"\"\"\n",
    "    \n",
    "    input_set = tf.concat([features['t0'], features['t1'], features['t2']], 1, name=\"input_set\")\n",
    "    \n",
    "    # Step 1 - Configure the network \n",
    "    with tf.variable_scope(\"2nd\", reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        first_hidden_layer_2nd = tf.layers.dense(features['t1'], 51, activation=tf.nn.relu,\n",
    "                                            #kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                            kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.001), \n",
    "                                            kernel_regularizer= tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                            name=\"first_layer_2nd\")\n",
    "        second_hidden_layer_2nd = tf.layers.dense(first_hidden_layer_2nd, 51, activation=tf.nn.relu, \n",
    "                                            #kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                            kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.001),\n",
    "                                            kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3), \n",
    "                                            name=\"second_layer_2nd\")\n",
    "        output_layer_2nd_na = tf.layers.dense(second_hidden_layer_2nd, 1, activation=None, \n",
    "                                          #kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                          kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.001),\n",
    "                                            kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                          name=\"output_layer_2nd_na\")\n",
    "        output_layer_2nd = tf.layers.dense(second_hidden_layer_2nd, 1, activation=tf.nn.sigmoid, \n",
    "                                          #kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                          kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.001),\n",
    "                                            kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                          name=\"output_layer_2nd\")\n",
    "        \n",
    "        #tau_1 = 1*output_layer_2nd_ind + 2*(1-output_layer_2nd_ind)\n",
    "        \n",
    "        # Define reward and optimizer\n",
    "        one = tf.constant(1, dtype=tf.float64)\n",
    "        reward_2nd = tf.add(tf.multiply(output_layer_2nd, features['t1']), \n",
    "                        tf.multiply((one-output_layer_2nd), features['t2']), \n",
    "                       name = \"reward_2nd\")\n",
    "    \n",
    "        rAvg_2nd = tf.reduce_mean(reward_2nd) \n",
    "        cost_2nd = tf.scalar_mul(-1,rAvg_2nd)\n",
    "        op2 = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "    \n",
    "        \n",
    "        second_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"2nd\")\n",
    "        train_op2 = op2.minimize(cost_2nd, var_list=second_train_vars)\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"1st\", reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        first_hidden_layer_1st = tf.layers.dense(features['t0'], 51, activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.001),\n",
    "                                            kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3), \n",
    "                                            #kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                            name=\"first_layer_1st\")\n",
    "        second_hidden_layer_1st = tf.layers.dense(first_hidden_layer_1st, 51, activation=tf.nn.relu, \n",
    "                                            kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.001), \n",
    "                                            kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                            #kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                            name=\"second_layer_1st\")\n",
    "        \n",
    "        output_layer_1st_na = tf.layers.dense(second_hidden_layer_1st, 1, activation=None,\n",
    "                                          kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.001),\n",
    "                                            kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                          #kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                          name=\"output_layer_1st_na\")\n",
    "        output_layer_1st = tf.layers.dense(second_hidden_layer_1st, 1, activation=tf.nn.sigmoid, \n",
    "                                          kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.001),\n",
    "                                            kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                          #kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                          name=\"output_layer_1st\")\n",
    "        \n",
    "    \n",
    "    with tf.get_default_graph().control_dependencies([train_op2]):\n",
    "        output_layer_2nd_ind = tf.cast(tf.clip_by_value(tf.sign(output_layer_2nd_na), 0, 2), \n",
    "                                       dtype=tf.int32, name=\"output_layer_2nd_ind\")\n",
    "        \n",
    "        tau_1 = 1*output_layer_2nd_ind + 2*(1-output_layer_2nd_ind)\n",
    "        \n",
    "        col_1 = tf.reshape(tf.range(tf.shape(tau_1)[0]), shape=tf.shape(tau_1), name=\"col_1\")\n",
    "        indices_1 = tf.concat([col_1, tau_1], 1, name=\"indices_1\")\n",
    "        g_1 = tf.gather_nd(input_set, indices=indices_1, name=\"g_1\")\n",
    "    \n",
    "        reward_1st = tf.add(tf.multiply(output_layer_1st, features['t0']), \n",
    "                            tf.multiply((one-output_layer_1st), g_1), \n",
    "                            name = \"reward_1st\")\n",
    "        rAvg_1st = tf.reduce_mean(reward_1st)\n",
    "        cost_1st = tf.scalar_mul(-1,rAvg_1st)\n",
    "    \n",
    "        op1 = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        \n",
    "        first_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"1st\")\n",
    "        train_op1 = op1.minimize(cost_1st, var_list=first_train_vars)\n",
    "    \n",
    "    \n",
    "    with tf.get_default_graph().control_dependencies([train_op2, train_op1]):\n",
    "        output_layer_1st_ind = tf.cast(tf.clip_by_value(tf.sign(output_layer_1st_na), 0, 2), \n",
    "                                       dtype=tf.int32, name=\"output_layer_1st_ind\")\n",
    "        \n",
    "        \n",
    "        tau_0 = (0*output_layer_1st_ind + 1*output_layer_2nd_ind*(1-output_layer_1st_ind)\n",
    "                +2*(1-output_layer_1st_ind)*(1-output_layer_2nd_ind))\n",
    "        indices_0 = tf.concat([col_1, tau_0], 1, name=\"indices_0\")\n",
    "        g_0 = tf.gather_nd(input_set, indices=indices_0, name=\"g_0\")\n",
    "        \n",
    "    \n",
    "        price = tf.reduce_mean(g_0, name=\"price\")\n",
    "    \n",
    "    global_step = tf.train.get_global_step()\n",
    "    update_global_step = tf.assign(global_step, global_step + 1, name = 'update_global_step')\n",
    "    \n",
    "    train_op =tf.group(train_op1, train_op2)\n",
    "    cost = cost_1st+cost_2nd \n",
    "    \n",
    "    op_ = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "    train_op_ =op_.minimize(cost)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=price,\n",
    "            evaluation_hooks=None)\n",
    "       \n",
    "    \n",
    "    # Provide an estimator spec for `ModeKeys.PREDICT`.\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions={\"price\": price})\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, \n",
    "            loss=cost_1st, \n",
    "            train_op=tf.group(train_op, update_global_step))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmplsusxzqo\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmplsusxzqo', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11c381f28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function my_model_fn at 0x18203b9d08>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "nn = tf.estimator.Estimator(model_fn=my_model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmplsusxzqo/model.ckpt.\n",
      "INFO:tensorflow:loss = -3.5703124811997005, step = 1\n",
      "INFO:tensorflow:global_step/sec: 163.59\n",
      "INFO:tensorflow:loss = -3.468976812358656, step = 101 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.079\n",
      "INFO:tensorflow:loss = -3.7000767361728792, step = 201 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.355\n",
      "INFO:tensorflow:loss = -3.377028461643883, step = 301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.954\n",
      "INFO:tensorflow:loss = -3.724929109447869, step = 401 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.189\n",
      "INFO:tensorflow:loss = -3.89612278458802, step = 501 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.491\n",
      "INFO:tensorflow:loss = -3.8181067643679634, step = 601 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.223\n",
      "INFO:tensorflow:loss = -3.8805720026899313, step = 701 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.475\n",
      "INFO:tensorflow:loss = -4.049680432178736, step = 801 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.067\n",
      "INFO:tensorflow:loss = -4.051378651406928, step = 901 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.753\n",
      "INFO:tensorflow:loss = -3.7781888720023122, step = 1001 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.792\n",
      "INFO:tensorflow:loss = -3.876472102082083, step = 1101 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.203\n",
      "INFO:tensorflow:loss = -4.045731883326231, step = 1201 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.138\n",
      "INFO:tensorflow:loss = -3.801019462956499, step = 1301 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.094\n",
      "INFO:tensorflow:loss = -3.7654796782099806, step = 1401 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.091\n",
      "INFO:tensorflow:loss = -4.121746122618797, step = 1501 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.286\n",
      "INFO:tensorflow:loss = -4.021749525931289, step = 1601 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.747\n",
      "INFO:tensorflow:loss = -4.133358703275034, step = 1701 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.202\n",
      "INFO:tensorflow:loss = -4.042081779319558, step = 1801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.002\n",
      "INFO:tensorflow:loss = -4.153145657860938, step = 1901 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.649\n",
      "INFO:tensorflow:loss = -4.487262055439453, step = 2001 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.419\n",
      "INFO:tensorflow:loss = -4.401028270778545, step = 2101 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.777\n",
      "INFO:tensorflow:loss = -3.9896456442530805, step = 2201 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.781\n",
      "INFO:tensorflow:loss = -4.057689575838039, step = 2301 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.531\n",
      "INFO:tensorflow:loss = -4.0289646646483295, step = 2401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.101\n",
      "INFO:tensorflow:loss = -4.070637775960039, step = 2501 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.059\n",
      "INFO:tensorflow:loss = -4.226331329329394, step = 2601 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.519\n",
      "INFO:tensorflow:loss = -4.640033384257159, step = 2701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.415\n",
      "INFO:tensorflow:loss = -4.104898153978654, step = 2801 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.157\n",
      "INFO:tensorflow:loss = -4.216033835497937, step = 2901 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.345\n",
      "INFO:tensorflow:loss = -4.444691054663156, step = 3001 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.571\n",
      "INFO:tensorflow:loss = -3.9339773265929043, step = 3101 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.886\n",
      "INFO:tensorflow:loss = -4.08827803998085, step = 3201 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.523\n",
      "INFO:tensorflow:loss = -4.1211464207273885, step = 3301 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.051\n",
      "INFO:tensorflow:loss = -4.208103510892263, step = 3401 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.859\n",
      "INFO:tensorflow:loss = -4.46368540738551, step = 3501 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.684\n",
      "INFO:tensorflow:loss = -4.29455487026081, step = 3601 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.554\n",
      "INFO:tensorflow:loss = -3.8945962527362257, step = 3701 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.092\n",
      "INFO:tensorflow:loss = -4.247702657642761, step = 3801 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.978\n",
      "INFO:tensorflow:loss = -4.109924867016826, step = 3901 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.591\n",
      "INFO:tensorflow:loss = -4.548122972577528, step = 4001 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.156\n",
      "INFO:tensorflow:loss = -4.540340669295293, step = 4101 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.413\n",
      "INFO:tensorflow:loss = -4.470512032306042, step = 4201 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.786\n",
      "INFO:tensorflow:loss = -4.403826526332734, step = 4301 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.177\n",
      "INFO:tensorflow:loss = -4.321509594837435, step = 4401 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.314\n",
      "INFO:tensorflow:loss = -4.157835379653015, step = 4501 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.093\n",
      "INFO:tensorflow:loss = -4.236419266756281, step = 4601 (0.224 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4689 into /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmplsusxzqo/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: -4.17103143568467.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1820434748>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.train(input_fn=numpy_train_input_fn(dice), steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-27-14:03:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmplsusxzqo/model.ckpt-4689\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-27-14:03:59\n",
      "INFO:tensorflow:Saving dict for global step 4689: global_step = 4689, loss = 2.8472111\n",
      "Loss: 2.8472111\n"
     ]
    }
   ],
   "source": [
    "ev = nn.evaluate(input_fn=numpy_eval_input_fn(dice))\n",
    "print(\"Loss: %s\" % ev[\"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_eval = np.random.randint(low=1, high=7, size=(M, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-27-14:04:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmplsusxzqo/model.ckpt-4689\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-27-14:04:12\n",
      "INFO:tensorflow:Saving dict for global step 4689: global_step = 4689, loss = 2.815368\n",
      "Loss: 2.815368\n"
     ]
    }
   ],
   "source": [
    "ev_ck = nn.evaluate(input_fn=numpy_eval_input_fn(dice_eval))\n",
    "print(\"Loss: %s\" % ev_ck[\"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def predict_input_fn(dice_eval):\n",
    "#    return tf.estimator.inputs.numpy_input_fn(\n",
    "#         x={\"t0\": np.reshape(dice[:, 0].astype(float), (len(dice[:, 0]), 1)), \n",
    "#           \"t1\": np.reshape(dice[:, 1].astype(float), (len(dice[:, 1]), 1)), \n",
    "#           \"t2\": np.reshape(dice[:, 2].astype(float), (len(dice[:, 2]), 1))}, \n",
    "#        num_epochs = 1, \n",
    "#        shuffle = False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLexs]",
   "language": "python",
   "name": "conda-env-DLexs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
