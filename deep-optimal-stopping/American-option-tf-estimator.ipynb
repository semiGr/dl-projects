{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Optimal Stopping - Dice problem - Implementation with tensorflow estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import scipy\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating samples in the same format as before. In an $M \\times 3$ matrix the rows represent the outcomes,  i.e. the 3 consecutive tosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample size for training \n",
    "M = 30000\n",
    "\n",
    "# create a sample of M x 3\n",
    "# In this example we only consider 3 tosses, hence only two steps with choices to stop at\n",
    "dice = np.random.randint(low=1, high=7, size=(M, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 samples: \n",
      "[[5 3 4]\n",
      " [5 4 5]\n",
      " [6 4 3]\n",
      " [6 3 3]\n",
      " [1 3 2]\n",
      " [3 3 1]\n",
      " [1 2 5]\n",
      " [6 4 2]\n",
      " [1 4 5]\n",
      " [5 3 6]]\n"
     ]
    }
   ],
   "source": [
    "# see the first 10 paths from the samples generated above\n",
    "print(\"The first 10 samples: \")\n",
    "print(dice[:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the input functions for training and evaluation in tensorflow estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input function for training with estimator, and use the dice np dataset \n",
    "def numpy_train_input_fn(dice): \n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"t0\": np.reshape(dice[:, 0].astype(float), (len(dice[:, 0]), 1)), \n",
    "           \"t1\": np.reshape(dice[:, 1].astype(float), (len(dice[:, 1]), 1)), \n",
    "           \"t2\": np.reshape(dice[:, 2].astype(float), (len(dice[:, 2]), 1))},\n",
    "        batch_size = 64, \n",
    "        num_epochs = 25, \n",
    "        shuffle = True, \n",
    "        queue_capacity = 1000\n",
    "    )\n",
    "\n",
    "# define input function for evaluation\n",
    "def numpy_eval_input_fn(dice):\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"t0\": np.reshape(dice[:, 0].astype(float), (len(dice[:, 0]), 1)), \n",
    "           \"t1\": np.reshape(dice[:, 1].astype(float), (len(dice[:, 1]), 1)), \n",
    "           \"t2\": np.reshape(dice[:, 2].astype(float), (len(dice[:, 2]), 1))},\n",
    "        num_epochs = 1, \n",
    "        shuffle = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition\n",
    "\n",
    "The training function below can be defined with a conditional function, so that after a certain number of training steps the optimizer and cost function changes to another one. This is an alternative way to handle the trainings of two separate networks distinctly. Remove the comments $\\#$ from the training mode definition in the code below to use this implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model_fn(features, mode, params):  \n",
    "    \n",
    "    \"\"\"Defining the custon architecture\"\"\"\n",
    "    \n",
    "    input_set = tf.concat([features['t0'], features['t1'], features['t2']], 1, name=\"input_set\")\n",
    "    \n",
    "    # Step 1 - Configure the network \n",
    "    with tf.variable_scope(\"2nd\", reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        first_hidden_layer_2nd = tf.layers.dense(features['t1'], 51, activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                            #kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01), \n",
    "                                            #kernel_regularizer= tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                            name=\"first_layer_2nd\")\n",
    "        second_hidden_layer_2nd = tf.layers.dense(first_hidden_layer_2nd, 51, activation=tf.nn.relu, \n",
    "                                            kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                            #kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                                            #kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3), \n",
    "                                            name=\"second_layer_2nd\")\n",
    "        logits_2nd = tf.layers.dense(second_hidden_layer_2nd, 1, activation=None, \n",
    "                                          kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                          #kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                                          #kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                          name=\"logits_2nd\")\n",
    "        F_theta_2nd = tf.nn.sigmoid(logits_2nd, name=\"F_theta_2nd\")\n",
    "        f_theta_2nd = tf.cast(tf.clip_by_value(tf.sign(logits_2nd), 0, 2), \n",
    "                                       dtype=tf.int32, name=\"f_theta_2nd\")\n",
    "        \n",
    "        #tau_1 = 1*output_layer_2nd_ind + 2*(1-output_layer_2nd_ind)\n",
    "        \n",
    "        # Define reward and optimizer\n",
    "        one = tf.constant(1, dtype=tf.float64)\n",
    "        reward_2nd = tf.add(tf.multiply(F_theta_2nd, features['t1']), \n",
    "                        tf.multiply((one-F_theta_2nd), features['t2']), \n",
    "                       name = \"reward_2nd\")\n",
    "    \n",
    "        rAvg_2nd = tf.reduce_mean(reward_2nd) \n",
    "        cost_2nd = tf.scalar_mul(-1,rAvg_2nd)\n",
    "        op2 = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    \n",
    "        \n",
    "        second_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"2nd\")\n",
    "        train_op2 = op2.minimize(cost_2nd, var_list=second_train_vars)\n",
    "    \n",
    "    \n",
    "    tau_1 = 1*f_theta_2nd + 2*(1-f_theta_2nd)\n",
    "        \n",
    "    col_1 = tf.reshape(tf.range(tf.shape(tau_1)[0]), shape=tf.shape(tau_1), name=\"col_1\")\n",
    "    indices_1 = tf.concat([col_1, tau_1], 1, name=\"indices_1\")\n",
    "    g_1 = tf.gather_nd(input_set, indices=indices_1, name=\"g_1\")\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"1st\", reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        first_hidden_layer_1st = tf.layers.dense(features['t0'], 51, activation=tf.nn.relu,\n",
    "                                            #kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                                            #kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3), \n",
    "                                            kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                            name=\"first_layer_1st\")\n",
    "        second_hidden_layer_1st = tf.layers.dense(first_hidden_layer_1st, 51, activation=tf.nn.relu, \n",
    "                                            #kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01), \n",
    "                                            #kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                            kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                            name=\"second_layer_1st\")\n",
    "        \n",
    "        logits_1st = tf.layers.dense(second_hidden_layer_1st, 1, activation=None,\n",
    "                                          #kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                                          #kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.3),\n",
    "                                          kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                                          name=\"logits_1st\")\n",
    "        F_theta_1st = tf.nn.sigmoid(logits_1st, name=\"output_layer_1st\")\n",
    "        f_theta_1st = tf.cast(tf.clip_by_value(tf.sign(logits_1st), 0, 2), \n",
    "                                       dtype=tf.int32, name=\"f_theta_1st\")\n",
    "    \n",
    "        reward_1st = tf.add(tf.multiply(F_theta_1st, features['t0']), \n",
    "                            tf.multiply((one-F_theta_1st), g_1), name = \"reward_1st\")\n",
    "        rAvg_1st = tf.reduce_mean(reward_1st)\n",
    "        cost_1st = tf.scalar_mul(-1,rAvg_1st)\n",
    "    \n",
    "        op1 = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        \n",
    "        first_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"1st\")\n",
    "        train_op1 = op1.minimize(cost_1st, var_list=first_train_vars)\n",
    "\n",
    "        \n",
    "    tau_0 = (0*f_theta_1st + 1*f_theta_2nd*(1-f_theta_1st)\n",
    "                +2*(1-f_theta_1st)*(1-f_theta_2nd))\n",
    "    col_0 = tf.reshape(tf.range(tf.shape(tau_0)[0]), shape=tf.shape(tau_0), name=\"col_0\")\n",
    "    indices_0 = tf.concat([col_0, tau_0], 1, name=\"indices_0\")\n",
    "    g_0 = tf.gather_nd(input_set, indices=indices_0, name=\"g_0\")\n",
    "        \n",
    "    \n",
    "    price = tf.reduce_mean(g_0, name=\"price\")\n",
    "    \n",
    "    global_step = tf.train.get_global_step()\n",
    "    update_global_step = tf.assign(global_step, global_step + 1, name = 'update_global_step')\n",
    "    \n",
    "    train_op =tf.group(train_op1, train_op2)\n",
    "    cost = cost_1st+cost_2nd \n",
    "    \n",
    "    op_ = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "    train_op_ =op_.minimize(cost)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=price,\n",
    "            evaluation_hooks=None)\n",
    "       \n",
    "    \n",
    "    # Provide an estimator spec for `ModeKeys.PREDICT`.\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions={\"price\": price})\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, \n",
    "            loss= cost,  #tf.cond((global_step < 5000), lambda: cost_2nd, lambda: cost_1st), \n",
    "            train_op= tf.group(train_op, update_global_step),\n",
    "            #tf.cond((global_step < 5000), lambda: tf.group(train_op2, update_global_step), \n",
    "                     #       lambda: tf.group(train_op1, update_global_step)),#tf.group(train_op, update_global_step), \n",
    "            training_hooks=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a folder, where the model will be saved\n",
    "MODEL_DIR = '/Users/Cellini/Desktop/Quant/DL Udacity/DLexs/Estimator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmpl4esn6bg\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmpl4esn6bg', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10e57b400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function my_model_fn at 0x10eef5488>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "nn = tf.estimator.Estimator(model_fn=my_model_fn) #, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmpl4esn6bg/model.ckpt.\n",
      "INFO:tensorflow:loss = -6.53976675783962, step = 1\n",
      "INFO:tensorflow:global_step/sec: 170.713\n",
      "INFO:tensorflow:loss = -7.460640595203019, step = 101 (0.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.574\n",
      "INFO:tensorflow:loss = -8.690484986710391, step = 201 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.024\n",
      "INFO:tensorflow:loss = -8.390074759993746, step = 301 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.322\n",
      "INFO:tensorflow:loss = -8.94561356016597, step = 401 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.358\n",
      "INFO:tensorflow:loss = -9.175860628462049, step = 501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.198\n",
      "INFO:tensorflow:loss = -8.765482925498134, step = 601 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.61\n",
      "INFO:tensorflow:loss = -8.534998563540443, step = 701 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.381\n",
      "INFO:tensorflow:loss = -9.341547644420881, step = 801 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.695\n",
      "INFO:tensorflow:loss = -8.954212617350489, step = 901 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.271\n",
      "INFO:tensorflow:loss = -9.143150959615166, step = 1001 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.369\n",
      "INFO:tensorflow:loss = -8.86723137306566, step = 1101 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.977\n",
      "INFO:tensorflow:loss = -9.286294649214462, step = 1201 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.834\n",
      "INFO:tensorflow:loss = -8.828398657689029, step = 1301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.029\n",
      "INFO:tensorflow:loss = -9.156446248450411, step = 1401 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.673\n",
      "INFO:tensorflow:loss = -8.96096296240798, step = 1501 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.791\n",
      "INFO:tensorflow:loss = -9.110835741891382, step = 1601 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.377\n",
      "INFO:tensorflow:loss = -8.230149822874926, step = 1701 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.622\n",
      "INFO:tensorflow:loss = -8.82150084527665, step = 1801 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.327\n",
      "INFO:tensorflow:loss = -8.793537682087143, step = 1901 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.144\n",
      "INFO:tensorflow:loss = -8.650505961372591, step = 2001 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.104\n",
      "INFO:tensorflow:loss = -9.177498643221282, step = 2101 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.679\n",
      "INFO:tensorflow:loss = -9.48795433807261, step = 2201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.366\n",
      "INFO:tensorflow:loss = -9.11789403667149, step = 2301 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.415\n",
      "INFO:tensorflow:loss = -8.532128814548575, step = 2401 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.905\n",
      "INFO:tensorflow:loss = -8.550300149656547, step = 2501 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.74\n",
      "INFO:tensorflow:loss = -8.963592716366081, step = 2601 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.285\n",
      "INFO:tensorflow:loss = -9.710945977135392, step = 2701 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.064\n",
      "INFO:tensorflow:loss = -9.138895800438302, step = 2801 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.914\n",
      "INFO:tensorflow:loss = -9.491131103274135, step = 2901 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.563\n",
      "INFO:tensorflow:loss = -8.007452410918138, step = 3001 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.591\n",
      "INFO:tensorflow:loss = -9.027390338868674, step = 3101 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.511\n",
      "INFO:tensorflow:loss = -9.181822057054026, step = 3201 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.324\n",
      "INFO:tensorflow:loss = -8.24903556635758, step = 3301 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.017\n",
      "INFO:tensorflow:loss = -8.849697014178737, step = 3401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.538\n",
      "INFO:tensorflow:loss = -8.78725437733861, step = 3501 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.255\n",
      "INFO:tensorflow:loss = -8.980779270466027, step = 3601 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.373\n",
      "INFO:tensorflow:loss = -8.791712231785475, step = 3701 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.263\n",
      "INFO:tensorflow:loss = -8.76925923822987, step = 3801 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.207\n",
      "INFO:tensorflow:loss = -8.78493014084241, step = 3901 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.341\n",
      "INFO:tensorflow:loss = -8.924600329621155, step = 4001 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.034\n",
      "INFO:tensorflow:loss = -8.270138069193898, step = 4101 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.36\n",
      "INFO:tensorflow:loss = -9.146151542393252, step = 4201 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.878\n",
      "INFO:tensorflow:loss = -8.784502792057019, step = 4301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.418\n",
      "INFO:tensorflow:loss = -9.034842719212602, step = 4401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.548\n",
      "INFO:tensorflow:loss = -8.679533861472612, step = 4501 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.641\n",
      "INFO:tensorflow:loss = -8.754049236809854, step = 4601 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.693\n",
      "INFO:tensorflow:loss = -9.32629212784043, step = 4701 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.524\n",
      "INFO:tensorflow:loss = -8.87033712035958, step = 4801 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.57\n",
      "INFO:tensorflow:loss = -9.317173142948535, step = 4901 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.893\n",
      "INFO:tensorflow:loss = -8.98594953582034, step = 5001 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.88\n",
      "INFO:tensorflow:loss = -8.779172856004926, step = 5101 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.483\n",
      "INFO:tensorflow:loss = -8.802875896083625, step = 5201 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.172\n",
      "INFO:tensorflow:loss = -8.924738761071087, step = 5301 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.769\n",
      "INFO:tensorflow:loss = -8.719873665515394, step = 5401 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.185\n",
      "INFO:tensorflow:loss = -9.41732998860961, step = 5501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.398\n",
      "INFO:tensorflow:loss = -8.788026842913213, step = 5601 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.359\n",
      "INFO:tensorflow:loss = -8.738236372960044, step = 5701 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.357\n",
      "INFO:tensorflow:loss = -8.568553212770386, step = 5801 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.285\n",
      "INFO:tensorflow:loss = -9.135654061565294, step = 5901 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.242\n",
      "INFO:tensorflow:loss = -9.03853066254588, step = 6001 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.503\n",
      "INFO:tensorflow:loss = -8.708889890222377, step = 6101 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.626\n",
      "INFO:tensorflow:loss = -8.758726370283991, step = 6201 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.168\n",
      "INFO:tensorflow:loss = -8.490460015281656, step = 6301 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.149\n",
      "INFO:tensorflow:loss = -8.889560015264216, step = 6401 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.109\n",
      "INFO:tensorflow:loss = -9.124721142172751, step = 6501 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.526\n",
      "INFO:tensorflow:loss = -8.399423774215277, step = 6601 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.187\n",
      "INFO:tensorflow:loss = -8.824163843915324, step = 6701 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.204\n",
      "INFO:tensorflow:loss = -9.033906490769832, step = 6801 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.222\n",
      "INFO:tensorflow:loss = -9.278024078034079, step = 6901 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.142\n",
      "INFO:tensorflow:loss = -9.071498973570698, step = 7001 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.729\n",
      "INFO:tensorflow:loss = -8.692356868779381, step = 7101 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.171\n",
      "INFO:tensorflow:loss = -9.54975695903789, step = 7201 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -9.37593895555818, step = 7301 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.383\n",
      "INFO:tensorflow:loss = -9.374970719121139, step = 7401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.949\n",
      "INFO:tensorflow:loss = -8.779772959078846, step = 7501 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.667\n",
      "INFO:tensorflow:loss = -8.895493546296922, step = 7601 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.337\n",
      "INFO:tensorflow:loss = -8.311999434464347, step = 7701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.355\n",
      "INFO:tensorflow:loss = -9.086880104976016, step = 7801 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.325\n",
      "INFO:tensorflow:loss = -8.930155733204494, step = 7901 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.501\n",
      "INFO:tensorflow:loss = -8.75438593015678, step = 8001 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.78\n",
      "INFO:tensorflow:loss = -8.955064631385218, step = 8101 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.074\n",
      "INFO:tensorflow:loss = -9.122290654925461, step = 8201 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.176\n",
      "INFO:tensorflow:loss = -9.196268472728358, step = 8301 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.227\n",
      "INFO:tensorflow:loss = -8.786610543803878, step = 8401 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.512\n",
      "INFO:tensorflow:loss = -8.097651126351481, step = 8501 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.023\n",
      "INFO:tensorflow:loss = -9.132796069061268, step = 8601 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.327\n",
      "INFO:tensorflow:loss = -9.011705365066533, step = 8701 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.05\n",
      "INFO:tensorflow:loss = -8.532212443954167, step = 8801 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.377\n",
      "INFO:tensorflow:loss = -8.737289533816238, step = 8901 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.597\n",
      "INFO:tensorflow:loss = -8.546866845684125, step = 9001 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.825\n",
      "INFO:tensorflow:loss = -8.81639486272546, step = 9101 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.416\n",
      "INFO:tensorflow:loss = -9.072251453960522, step = 9201 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.019\n",
      "INFO:tensorflow:loss = -9.400868384672057, step = 9301 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.467\n",
      "INFO:tensorflow:loss = -8.789056336463794, step = 9401 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.446\n",
      "INFO:tensorflow:loss = -9.377914414198973, step = 9501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.152\n",
      "INFO:tensorflow:loss = -8.536124955928445, step = 9601 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.072\n",
      "INFO:tensorflow:loss = -8.881341151851867, step = 9701 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.566\n",
      "INFO:tensorflow:loss = -9.00560971353963, step = 9801 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.265\n",
      "INFO:tensorflow:loss = -9.207019675467025, step = 9901 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.652\n",
      "INFO:tensorflow:loss = -8.7355919522292, step = 10001 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 549.447\n",
      "INFO:tensorflow:loss = -8.980464259343819, step = 10101 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.69\n",
      "INFO:tensorflow:loss = -8.81249376877821, step = 10201 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.969\n",
      "INFO:tensorflow:loss = -9.297357025787583, step = 10301 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.366\n",
      "INFO:tensorflow:loss = -9.36205524693779, step = 10401 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.571\n",
      "INFO:tensorflow:loss = -9.1750405322456, step = 10501 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.873\n",
      "INFO:tensorflow:loss = -9.5053676277862, step = 10601 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.566\n",
      "INFO:tensorflow:loss = -8.90966682510086, step = 10701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.721\n",
      "INFO:tensorflow:loss = -9.136713910969725, step = 10801 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.991\n",
      "INFO:tensorflow:loss = -8.624996247740851, step = 10901 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.612\n",
      "INFO:tensorflow:loss = -8.982664100108977, step = 11001 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.451\n",
      "INFO:tensorflow:loss = -8.948237662626012, step = 11101 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.442\n",
      "INFO:tensorflow:loss = -8.575194973325619, step = 11201 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.757\n",
      "INFO:tensorflow:loss = -8.963862713419957, step = 11301 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.186\n",
      "INFO:tensorflow:loss = -9.55273284380507, step = 11401 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.81\n",
      "INFO:tensorflow:loss = -8.538571775012805, step = 11501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.066\n",
      "INFO:tensorflow:loss = -8.029784694081759, step = 11601 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.107\n",
      "INFO:tensorflow:loss = -8.80541685946569, step = 11701 (0.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11720 into /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmpl4esn6bg/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: -8.902777607923017.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x181d6686d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.train(input_fn=numpy_train_input_fn(dice), steps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-17-23:23:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmpl4esn6bg/model.ckpt-11720\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-17-23:23:53\n",
      "INFO:tensorflow:Saving dict for global step 11720: global_step = 11720, loss = 4.6521053\n",
      "Price: 4.6521053\n"
     ]
    }
   ],
   "source": [
    "ev = nn.evaluate(input_fn=numpy_eval_input_fn(dice))\n",
    "print(\"Price: %s\" % ev[\"loss\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result \n",
    "The solver should produce a result around $4.6\\dots$, which is close to the analytical solution $28/6\\approx 4.66$. Evaluating the trained model on a separate, similarly sized sample, the result should be reasonably close, $4.6\\dots$, to the result obtained on the training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate sample for evaluation\n",
    "dice_eval = np.random.randint(low=1, high=7, size=(M, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-17-23:24:01\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/16/6vfzqvh50sv0n670v2qmktsw0000gn/T/tmpl4esn6bg/model.ckpt-11720\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-17-23:24:02\n",
      "INFO:tensorflow:Saving dict for global step 11720: global_step = 11720, loss = 4.6519947\n",
      "Price: 4.6519947\n"
     ]
    }
   ],
   "source": [
    "# Use the evaluation sample to get the price\n",
    "ev_ck = nn.evaluate(input_fn=numpy_eval_input_fn(dice_eval))\n",
    "print(\"Price: %s\" % ev_ck[\"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLexs]",
   "language": "python",
   "name": "conda-env-DLexs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
