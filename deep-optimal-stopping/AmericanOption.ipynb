{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Optimal Stopping\n",
    "\n",
    "Implementing the numerical solver for optimal stopping problems based on the article \n",
    "\"Deep Optimal Stopping\" - Sebastian Becker, Patrick Cheridito, Arnulf Jentzen \n",
    "(available at: https://arxiv.org/pdf/1804.05394.pdf)\n",
    "\n",
    "#### The problem:\n",
    "Roll a die once. You are offered the dollar amount the die shows. At this stage you are free to choose to take the money, or roll the die again (in which case no money is paid at this stage). Example: Say you rolled a 4, but decided to go on\n",
    "\n",
    "If you chose to roll again. After the second toss, the dollar amount the die shows is offered you again. You are free to choose to take the money, or toss the die again. Example: Now you rolled a 3, but decided to go on\n",
    "\n",
    "Provided you proceeded to the third round. The die is cast and you will have to take the dollar amount the die shows after the third roll, i.e. no more choice to stop. Example: You rolled a 5, the game terminates\n",
    "\n",
    "#### Question: How much are you willing to pay to participate in this game? In other words: whatâ€™s the fair value of this game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import scipy\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a sample used for training\n",
    "\n",
    "The data set will be a numpy array of the size $M\\times 3$, where each line represents one sample, i.e. $3$ tosses of a die, and $M$ is the number of samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample size for training \n",
    "M = 10000\n",
    "\n",
    "# create a sample of M x 3\n",
    "# In this example we only consider 3 tosses, hence only two steps with choices to stop at\n",
    "dice = np.random.randint(low=1, high=7, size=(M, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 samples: \n",
      "[[4 5 3]\n",
      " [6 5 1]\n",
      " [2 4 5]\n",
      " [5 1 5]\n",
      " [4 3 3]\n",
      " [1 3 2]\n",
      " [1 1 3]\n",
      " [1 4 5]\n",
      " [3 1 3]\n",
      " [3 4 6]]\n"
     ]
    }
   ],
   "source": [
    "# see the first 10 paths from the samples generated above\n",
    "print(\"The first 10 samples: \")\n",
    "print(dice[:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " define a function that slices batches from the samples \n",
    "          --- Variables: \n",
    "              - i : the i-th batch from the sample \n",
    "              - time : this is needed for the training, \n",
    "                       this is a variable that picks the right column from the sample \n",
    "              - batch_size : batch size; i.e. number of samples in one batch \n",
    "              - paths : matrix or tensor that contains the samples \n",
    "                        for the dice case, this is the numpy array of size Mx3 named dice\n",
    "          --- Output: \n",
    "              - returns the required batch in the right format for training \n",
    "'''\n",
    "\n",
    "def makeBatches(i, time, batch_size,  paths):\n",
    "    start_pos = i*batch_size\n",
    "    end_pos = (i+1)*batch_size\n",
    "    if end_pos > len(paths[:, 0]):\n",
    "        return np.reshape(paths[start_pos: , time], (len(paths[start_pos: , time]),1)) \n",
    "    else:\n",
    "        return np.reshape(paths[start_pos:end_pos, time], (batch_size, 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# defining hyperparameters for the feed forward NNs\n",
    "# -------------------------------------------------\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 25\n",
    "batch_size = 64\n",
    "\n",
    "n_input = 1\n",
    "# hidden layer size\n",
    "n_hidden_layer = 51 # number of nodes/size of hidden layer. in the paper, the choice is d+50, hence 51. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Building the graph structure with tf.Graph()\n",
    "'''\n",
    "\n",
    "dummyGraph = tf.Graph()\n",
    "\n",
    "\n",
    "with dummyGraph.as_default():\n",
    "   \n",
    "    with tf.variable_scope('2nd'):\n",
    "    \n",
    "        # weights and biases \n",
    "        weights = {\n",
    "            'hidden_layer_1': tf.Variable(tf.random_normal([n_input, n_hidden_layer], mean=0.0, stddev=0.01)), \n",
    "            'hidden_layer_2': tf.Variable(tf.random_normal([n_hidden_layer, n_hidden_layer], mean=0.0, stddev=0.01)),\n",
    "            'out': tf.Variable(tf.random_normal([n_hidden_layer, 1], mean=0.0, stddev=0.01))\n",
    "            }\n",
    "\n",
    "        biases = {\n",
    "            'hidden_layer_1': tf.Variable(tf.random_normal([n_hidden_layer], mean=0.0, stddev=0.01)),\n",
    "            'hidden_layer_2': tf.Variable(tf.random_normal([n_hidden_layer], mean=0.0, stddev=0.01)),\n",
    "            'out': tf.Variable(tf.random_normal([], mean=0.0, stddev=0.01))\n",
    "        }\n",
    "    \n",
    "        # tf graph input \n",
    "        x = tf.placeholder(\"float\", [None, 1])\n",
    "        x_prev = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "        x_flat = tf.reshape(x, [-1, n_input])\n",
    "        \n",
    "        # Hidden layer with RELU activation\n",
    "        layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer_1']),biases['hidden_layer_1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['hidden_layer_2']), biases['hidden_layer_2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "        # Output layer with linear activation\n",
    "        logits = {'logits': tf.add(tf.matmul(layer_2, weights['out']), biases['out'])}\n",
    "        F_theta = tf.nn.sigmoid(logits['logits'])\n",
    "\n",
    "        # Define reward and optimizer\n",
    "        one = tf.constant(1, dtype=tf.float32)\n",
    "        reward = (tf.multiply(F_theta, x) + tf.multiply((one-F_theta), x_prev))\n",
    "        rAvg = tf.reduce_mean(reward) \n",
    "\n",
    "        cost = tf.scalar_mul(-1,rAvg)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        opt_operation = opt.minimize(cost)\n",
    "        \n",
    "    # assemble tau for the next network, i.e. tau that describes the stopping times, which can be\n",
    "    # either 1 or 2\n",
    "    arg_1 = tf.placeholder(\"float\", [None, 1])\n",
    "    f_theta_1 = tf.cast(tf.clip_by_value(tf.sign(arg_1), 0, 5), dtype=tf.int32)\n",
    "    tau_1 = 1*f_theta_1 + 2*(1-f_theta_1)\n",
    "        \n",
    "    \n",
    "    with tf.variable_scope('1st'):\n",
    "    \n",
    "        # weights and biases \n",
    "        weights = {\n",
    "            'hidden_layer_1': tf.Variable(tf.random_normal([n_input, n_hidden_layer], mean=0.0, stddev=0.001)), \n",
    "            'hidden_layer_2': tf.Variable(tf.random_normal([n_hidden_layer, n_hidden_layer], mean=0.0, stddev=0.001)),\n",
    "            'out': tf.Variable(tf.random_normal([n_hidden_layer, 1], mean=0.0, stddev=0.001))\n",
    "            }\n",
    "\n",
    "        biases = {\n",
    "            'hidden_layer_1': tf.Variable(tf.random_normal([n_hidden_layer], mean=0.0, stddev=0.001)),\n",
    "            'hidden_layer_2': tf.Variable(tf.random_normal([n_hidden_layer], mean=0.0, stddev=0.001)),\n",
    "            'out': tf.Variable(tf.random_normal([], mean=0.0, stddev=0.001))\n",
    "        }\n",
    "    \n",
    "        # tf graph input \n",
    "        x = tf.placeholder(\"float\", [None, 1])\n",
    "        x_prev = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "        x_flat = tf.reshape(x, [-1, n_input])\n",
    "        \n",
    "        # Hidden layer with RELU activation\n",
    "        layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer_1']),biases['hidden_layer_1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['hidden_layer_2']), biases['hidden_layer_2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "        # Output layer with linear activation\n",
    "        logits = {'logits': tf.add(tf.matmul(layer_2, weights['out']), biases['out'])}\n",
    "        F_theta = tf.nn.sigmoid(logits['logits'])\n",
    "\n",
    "        # Define reward and optimizer\n",
    "        one = tf.constant(1, dtype=tf.float32)\n",
    "        reward = (tf.multiply(F_theta, x) + tf.multiply((one-F_theta), x_prev))\n",
    "        rAvg = tf.reduce_mean(reward) \n",
    "\n",
    "        cost = tf.scalar_mul(-1,rAvg)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        opt_operation = opt.minimize(cost)\n",
    "    \n",
    "    # assemble tau that describes the stopping time, which can be 0, 1, or 2. In other words, this is the \n",
    "    # stopping time for the entire time span of the model \n",
    "    arg_0 = tf.placeholder(\"float\", [None, 1])\n",
    "    f_theta_0 = tf.cast(tf.clip_by_value(tf.sign(arg_0), 0, 5), dtype=tf.int32)\n",
    "    tau_0 = 0*f_theta_0 + 1*f_theta_1*(1-f_theta_0)+2*(1-f_theta_0)*(1-f_theta_1)\n",
    "    \n",
    "    \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: -3.5785875\n",
      "cost: -3.8937650\n",
      "epoch: 0 \n",
      "cost: -4.1967888\n",
      "cost: -4.3118210\n",
      "epoch: 1 \n",
      "cost: -4.3134398\n",
      "cost: -4.3452549\n",
      "epoch: 2 \n",
      "cost: -4.3278174\n",
      "cost: -4.3582611\n",
      "epoch: 3 \n",
      "cost: -4.3350372\n",
      "cost: -4.3649092\n",
      "epoch: 4 \n",
      "cost: -4.3387208\n",
      "cost: -4.3685231\n",
      "epoch: 5 \n",
      "cost: -4.3406010\n",
      "cost: -4.3706074\n",
      "epoch: 6 \n",
      "cost: -4.3416348\n",
      "cost: -4.3718815\n",
      "epoch: 7 \n",
      "cost: -4.3422527\n",
      "cost: -4.3727016\n",
      "epoch: 8 \n",
      "cost: -4.3426485\n",
      "cost: -4.3732543\n",
      "epoch: 9 \n",
      "cost: -4.3429146\n",
      "cost: -4.3736401\n",
      "epoch: 10 \n",
      "cost: -4.3431005\n",
      "cost: -4.3739185\n",
      "epoch: 11 \n",
      "cost: -4.3432355\n",
      "cost: -4.3741255\n",
      "epoch: 12 \n",
      "cost: -4.3433347\n",
      "cost: -4.3742819\n",
      "epoch: 13 \n",
      "cost: -4.3434105\n",
      "cost: -4.3744035\n",
      "epoch: 14 \n",
      "cost: -4.3434677\n",
      "cost: -4.3744993\n",
      "epoch: 15 \n",
      "cost: -4.3435140\n",
      "cost: -4.3745761\n",
      "epoch: 16 \n",
      "cost: -4.3435502\n",
      "cost: -4.3746386\n",
      "epoch: 17 \n",
      "cost: -4.3435798\n",
      "cost: -4.3746896\n",
      "epoch: 18 \n",
      "cost: -4.3436036\n",
      "cost: -4.3747320\n",
      "epoch: 19 \n",
      "cost: -4.3436236\n",
      "cost: -4.3747673\n",
      "epoch: 20 \n",
      "cost: -4.3436403\n",
      "cost: -4.3747969\n",
      "epoch: 21 \n",
      "cost: -4.3436546\n",
      "cost: -4.3748221\n",
      "epoch: 22 \n",
      "cost: -4.3436661\n",
      "cost: -4.3748436\n",
      "epoch: 23 \n",
      "cost: -4.3436766\n",
      "cost: -4.3748622\n",
      "epoch: 24 \n",
      "cost: -3.9533730\n",
      "cost: -4.0765548\n",
      "epoch: 24 \n",
      "cost: -4.5023546\n",
      "cost: -4.5526285\n",
      "epoch: 24 \n",
      "cost: -4.7643414\n",
      "cost: -4.5928893\n",
      "epoch: 24 \n",
      "cost: -4.7865291\n",
      "cost: -4.6041603\n",
      "epoch: 24 \n",
      "cost: -4.7951579\n",
      "cost: -4.6101961\n",
      "epoch: 24 \n",
      "cost: -4.8000641\n",
      "cost: -4.6140652\n",
      "epoch: 24 \n",
      "cost: -4.8033094\n",
      "cost: -4.6167440\n",
      "epoch: 24 \n",
      "cost: -4.8055868\n",
      "cost: -4.6186643\n",
      "epoch: 24 \n",
      "cost: -4.8072224\n",
      "cost: -4.6200719\n",
      "epoch: 24 \n",
      "cost: -4.8084087\n",
      "cost: -4.6211224\n",
      "epoch: 24 \n",
      "cost: -4.8092785\n",
      "cost: -4.6219168\n",
      "epoch: 24 \n",
      "cost: -4.8099236\n",
      "cost: -4.6225233\n",
      "epoch: 24 \n",
      "cost: -4.8104091\n",
      "cost: -4.6229906\n",
      "epoch: 24 \n",
      "cost: -4.8107805\n",
      "cost: -4.6233540\n",
      "epoch: 24 \n",
      "cost: -4.8110695\n",
      "cost: -4.6236396\n",
      "epoch: 24 \n",
      "cost: -4.8112965\n",
      "cost: -4.6238656\n",
      "epoch: 24 \n",
      "cost: -4.8114786\n",
      "cost: -4.6240463\n",
      "epoch: 24 \n",
      "cost: -4.8116264\n",
      "cost: -4.6241922\n",
      "epoch: 24 \n",
      "cost: -4.8117485\n",
      "cost: -4.6243114\n",
      "epoch: 24 \n",
      "cost: -4.8118491\n",
      "cost: -4.6244092\n",
      "epoch: 24 \n",
      "cost: -4.8119340\n",
      "cost: -4.6244907\n",
      "epoch: 24 \n",
      "cost: -4.8120050\n",
      "cost: -4.6245589\n",
      "epoch: 24 \n",
      "cost: -4.8120661\n",
      "cost: -4.6246161\n",
      "epoch: 24 \n",
      "cost: -4.8121185\n",
      "cost: -4.6246643\n",
      "epoch: 24 \n",
      "cost: -4.8121648\n",
      "cost: -4.6247058\n",
      "epoch: 24 \n",
      "The trained model is saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=dummyGraph) as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(len(dice[:, 0])/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x = makeBatches(i, 1, batch_size,  dice) # getting the correct input slices (batches)\n",
    "            batch_x_prev = makeBatches(i, 2, batch_size,  dice) # getting the correct input slices (batches)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            loss_val = sess.run(dummyGraph.get_operation_by_name(\"2nd/Adam\"), \n",
    "                                feed_dict={dummyGraph.get_tensor_by_name(\"2nd/Placeholder:0\"): batch_x, \n",
    "                                           dummyGraph.get_tensor_by_name(\"2nd/Placeholder_1:0\"): batch_x_prev})\n",
    "            \n",
    "            \n",
    "            if i%100==0:\n",
    "                w_value = sess.run(dummyGraph.get_tensor_by_name(\"2nd/mul:0\"), \n",
    "                                   feed_dict={dummyGraph.get_tensor_by_name(\"2nd/Placeholder:0\"): batch_x, \n",
    "                                           dummyGraph.get_tensor_by_name(\"2nd/Placeholder_1:0\"): batch_x_prev})\n",
    "                print(\"cost: {b:.7f}\".format(b=w_value))\n",
    "                #print(sess.run(F_theta[:5,:], feed_dict={x: batch_x, x_prev: batch_x_prev}))\n",
    "                #print(\"weights\")\n",
    "                #print(sess.run(weights['hidden_layer_1']))\n",
    "        print(\"epoch: %i \" %epoch)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    h = np.reshape(dice[:,1].astype(np.float32), [M,1])\n",
    "    h_ = sess.run(dummyGraph.get_tensor_by_name(\"2nd/Add_2:0\"), \n",
    "                  feed_dict={dummyGraph.get_tensor_by_name(\"2nd/Placeholder:0\"): h}).astype(np.int32)\n",
    "    tau_test = sess.run(dummyGraph.get_tensor_by_name(\"add:0\"), \n",
    "                         feed_dict={arg_1: h_}).astype(np.int32)\n",
    "    \n",
    "    dice_tau = np.array([dice[x, tau_test[x,0]] for x in range(len(tau_test[:,0]))])\n",
    "    dice_tau = np.reshape(dice_tau, [len(dice[:,1]), 1]) \n",
    "    \n",
    "    for epoch_ in range(training_epochs):\n",
    "        total_batch_ = int(len(dice[:, 0])/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch_):\n",
    "            batch_x0 = makeBatches(i, 0, batch_size,  dice) # getting the correct input slices (batches)\n",
    "            batch_x_prev0 = makeBatches(i, 0, batch_size,  dice_tau) # getting the correct input slices (batches)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            loss_val = sess.run(dummyGraph.get_operation_by_name(\"1st/Adam\"), \n",
    "                                feed_dict={dummyGraph.get_tensor_by_name(\"1st/Placeholder:0\"): batch_x0, \n",
    "                                           dummyGraph.get_tensor_by_name(\"1st/Placeholder_1:0\"): batch_x_prev0})\n",
    "            \n",
    "            \n",
    "            if i%100==0:\n",
    "                w_value_ = sess.run(dummyGraph.get_tensor_by_name(\"1st/mul:0\"), \n",
    "                                   feed_dict={dummyGraph.get_tensor_by_name(\"1st/Placeholder:0\"): batch_x0, \n",
    "                                           dummyGraph.get_tensor_by_name(\"1st/Placeholder_1:0\"): batch_x_prev0})\n",
    "                print(\"cost: {b:.7f}\".format(b=w_value_))\n",
    "                #print(sess.run(F_theta[:5,:], feed_dict={x: batch_x, x_prev: batch_x_prev}))\n",
    "                #print(\"weights\")\n",
    "                #print(sess.run(weights['hidden_layer_1']))\n",
    "        print(\"epoch: %i \" %epoch)\n",
    "    \n",
    "    \n",
    "    \n",
    "    g = np.reshape(dice[:,0].astype(np.float32), [M,1])\n",
    "    g_ = sess.run(dummyGraph.get_tensor_by_name(\"1st/Add_2:0\"), \n",
    "                  feed_dict={dummyGraph.get_tensor_by_name(\"1st/Placeholder:0\"): g}).astype(np.int32)\n",
    "    \n",
    "    \n",
    "    tau_test_2 = sess.run(dummyGraph.get_tensor_by_name(\"add_2:0\"), \n",
    "                         feed_dict={arg_0: g_, arg_1: h_}).astype(np.int32)\n",
    "    \n",
    "    d_ = np.array([dice[x, tau_test_2[x,0]] for x in range(len(tau_test_2[:,0]))])\n",
    "    d_ = np.reshape(d_, [len(dice[:,1]), 1]) \n",
    "    \n",
    "    saver.save(sess, './train_model_prec.ckpt')\n",
    "    print(\"The trained model is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained stopping time - tau_0: \n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "The relevant part of the input sample - dice\n",
      "corresponding to the trained stopping time\n",
      "[[6 5 4]\n",
      " [4 6 6]\n",
      " [6 2 1]\n",
      " [1 6 6]\n",
      " [5 3 3]\n",
      " [6 5 5]\n",
      " [3 2 2]\n",
      " [4 4 5]\n",
      " [6 2 1]\n",
      " [4 6 2]\n",
      " [3 2 2]\n",
      " [1 4 4]\n",
      " [6 1 5]\n",
      " [1 4 1]\n",
      " [3 5 6]]\n",
      "The value on the die at stopping\n",
      "[[6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [2]\n",
      " [4]\n",
      " [6]\n",
      " [6]\n",
      " [2]\n",
      " [4]\n",
      " [6]\n",
      " [4]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "# printing some parts of the result\n",
    "\n",
    "# the trained stopping times that indicates where we should stop\n",
    "print(\"The trained stopping time - tau_0: \")\n",
    "print(tau_test_2[10:25])\n",
    "\n",
    "# the relevant part of the training sample\n",
    "print(\"The relevant part of the input sample - dice\")\n",
    "print(\"corresponding to the trained stopping time\")\n",
    "print(dice[10:25])\n",
    "\n",
    "# the value on the die that's picked by the trained stopping time \n",
    "print(\"The value on the die at stopping\")\n",
    "print(d_[10:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Price - evaluation on a separate sample set\n",
    "# -------------------------------------------\n",
    "\n",
    "# create a sample of M x 3 for evaluation\n",
    "dice_eval = np.random.randint(low=1, high=7, size=(M, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./train_model_prec.ckpt\n",
      "The fair value of the game: 4.668600\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph and evaluate the trained stopping time on the evaluation sample \n",
    "with tf.Session(graph=dummyGraph) as sess:\n",
    "    saver.restore(sess, './train_model_prec.ckpt')\n",
    "    \n",
    "    h = np.reshape(dice_eval[:,1].astype(np.float32), [len(dice[:,0]),1])\n",
    "    h_ = sess.run(dummyGraph.get_tensor_by_name(\"2nd/Add_2:0\"), \n",
    "                  feed_dict={dummyGraph.get_tensor_by_name(\"2nd/Placeholder:0\"): h}).astype(np.int32)\n",
    "    \n",
    "    g = np.reshape(dice_eval[:,0].astype(np.float32), [len(dice[:,0]),1])\n",
    "    g_ = sess.run(dummyGraph.get_tensor_by_name(\"1st/Add_2:0\"), \n",
    "                  feed_dict={dummyGraph.get_tensor_by_name(\"1st/Placeholder:0\"): g}).astype(np.int32)\n",
    "    \n",
    "    tau_eval = sess.run(dummyGraph.get_tensor_by_name(\"add_2:0\"), \n",
    "                         feed_dict={arg_0: g_, arg_1: h_}).astype(np.int32)\n",
    "    \n",
    "    d_ = np.array([dice_eval[x, tau_eval[x,0]] for x in range(len(tau_eval[:,0]))])\n",
    "    d_ = np.reshape(d_, [len(dice_eval[:,1]), 1]) \n",
    "    \n",
    "    Value = np.mean(d_)\n",
    "    print(\"The fair value of the game: %f\" %Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is fairly stable in the sense that with the above setting, the pricing should be around $4.6\\dots$, depending on the samples and training. It can be shown that the analytical solution, or fair price of the game is $28/6 \\approx 4.66$. Hence the numerical method produces a reasonably close result that matches to the first decimal. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLexs]",
   "language": "python",
   "name": "conda-env-DLexs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
